{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucius-yu/colab-tutorial/blob/master/kfold_average_dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "36YDxnK1lrIZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "KFlod Average on DNN for fashion mnist problem"
      ]
    },
    {
      "metadata": {
        "id": "lB3GSOXmmJkw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import liberary"
      ]
    },
    {
      "metadata": {
        "id": "eRzv1gDPl1rS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import log_loss, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IbNRQKbfmR6I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the data, preprocess the data, setup KFold CV"
      ]
    },
    {
      "metadata": {
        "id": "OfFCtNGkmZRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "03c540fe-28ff-4a93-ee1c-afa50095c2be"
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# load data\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# normalization\n",
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4N21PtV8nE8R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build the model"
      ]
    },
    {
      "metadata": {
        "id": "y1mtSaTanI3P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "  # build the model\n",
        "  model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                      tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "  model.compile(optimizer = tf.train.AdamOptimizer(learning_rate=0.0005),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ewIIHlOznc9Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train KFold Model with early stopping"
      ]
    },
    {
      "metadata": {
        "id": "6z--ikFwnmhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3801
        },
        "outputId": "354ec147-9afc-4116-ba68-09d95ccd2320"
      },
      "cell_type": "code",
      "source": [
        "# setup cv\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "# variables\n",
        "num_epochs=20\n",
        "\n",
        "# predictions\n",
        "test_preds = list()\n",
        "\n",
        "for train_index, validation_index in skf.split(training_images, training_labels):\n",
        "  print(\"TRAIN:\", len(train_index), \"Validation:\", len(validation_index))\n",
        "  \n",
        "  X_train, X_valid = training_images[train_index], training_images[validation_index]\n",
        "  y_train, y_valid = training_labels[train_index], training_labels[validation_index]\n",
        "  \n",
        "  dnn_model = get_model()\n",
        "  dnn_model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=num_epochs)\n",
        "  \n",
        "  # evaluate on test images\n",
        "  dnn_model.evaluate(test_images, test_labels)\n",
        "  \n",
        "  # record test_preds\n",
        "  test_preds.append(dnn_model.predict(test_images, batch_size=128))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: 48000 Validation: 12000\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 6s 134us/sample - loss: 0.5352 - acc: 0.8145 - val_loss: 0.4224 - val_acc: 0.8467\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 6s 127us/sample - loss: 0.3833 - acc: 0.8627 - val_loss: 0.3470 - val_acc: 0.8753\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 6s 125us/sample - loss: 0.3405 - acc: 0.8753 - val_loss: 0.3365 - val_acc: 0.8793\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 6s 124us/sample - loss: 0.3171 - acc: 0.8848 - val_loss: 0.3518 - val_acc: 0.8722\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 6s 129us/sample - loss: 0.2966 - acc: 0.8903 - val_loss: 0.3202 - val_acc: 0.8827\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 6s 125us/sample - loss: 0.2817 - acc: 0.8953 - val_loss: 0.3122 - val_acc: 0.8890\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 6s 127us/sample - loss: 0.2702 - acc: 0.8990 - val_loss: 0.3076 - val_acc: 0.8844\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 6s 129us/sample - loss: 0.2576 - acc: 0.9035 - val_loss: 0.3037 - val_acc: 0.8882\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 6s 134us/sample - loss: 0.2463 - acc: 0.9079 - val_loss: 0.3156 - val_acc: 0.8890\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 6s 126us/sample - loss: 0.2339 - acc: 0.9117 - val_loss: 0.3052 - val_acc: 0.8905\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 6s 130us/sample - loss: 0.2262 - acc: 0.9155 - val_loss: 0.3107 - val_acc: 0.8877\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 6s 125us/sample - loss: 0.2178 - acc: 0.9188 - val_loss: 0.3051 - val_acc: 0.8864\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 6s 129us/sample - loss: 0.2084 - acc: 0.9221 - val_loss: 0.3046 - val_acc: 0.8908\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 6s 132us/sample - loss: 0.2020 - acc: 0.9239 - val_loss: 0.2957 - val_acc: 0.8963\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 6s 131us/sample - loss: 0.1949 - acc: 0.9262 - val_loss: 0.3089 - val_acc: 0.8923\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 6s 132us/sample - loss: 0.1887 - acc: 0.9282 - val_loss: 0.3162 - val_acc: 0.8891\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 6s 132us/sample - loss: 0.1815 - acc: 0.9312 - val_loss: 0.3190 - val_acc: 0.8917\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 6s 131us/sample - loss: 0.1751 - acc: 0.9338 - val_loss: 0.3120 - val_acc: 0.8936\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 6s 134us/sample - loss: 0.1668 - acc: 0.9366 - val_loss: 0.3184 - val_acc: 0.8951\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 6s 130us/sample - loss: 0.1642 - acc: 0.9377 - val_loss: 0.3292 - val_acc: 0.8926\n",
            "10000/10000 [==============================] - 1s 60us/sample - loss: 0.3640 - acc: 0.8861\n",
            "TRAIN: 48000 Validation: 12000\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 6s 127us/sample - loss: 0.5279 - acc: 0.8163 - val_loss: 0.4571 - val_acc: 0.8319\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 6s 124us/sample - loss: 0.3837 - acc: 0.8611 - val_loss: 0.3741 - val_acc: 0.8614\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 6s 122us/sample - loss: 0.3440 - acc: 0.8749 - val_loss: 0.3558 - val_acc: 0.8695\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 6s 124us/sample - loss: 0.3168 - acc: 0.8846 - val_loss: 0.3519 - val_acc: 0.8702\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 6s 125us/sample - loss: 0.2981 - acc: 0.8900 - val_loss: 0.3475 - val_acc: 0.8727\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 6s 124us/sample - loss: 0.2813 - acc: 0.8968 - val_loss: 0.3257 - val_acc: 0.8813\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 6s 122us/sample - loss: 0.2681 - acc: 0.8991 - val_loss: 0.3171 - val_acc: 0.8834\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 6s 119us/sample - loss: 0.2559 - acc: 0.9041 - val_loss: 0.3134 - val_acc: 0.8873\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 6s 121us/sample - loss: 0.2450 - acc: 0.9090 - val_loss: 0.3210 - val_acc: 0.8846\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 6s 123us/sample - loss: 0.2366 - acc: 0.9112 - val_loss: 0.3275 - val_acc: 0.8819\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 6s 123us/sample - loss: 0.2271 - acc: 0.9145 - val_loss: 0.3100 - val_acc: 0.8886\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 6s 120us/sample - loss: 0.2181 - acc: 0.9171 - val_loss: 0.3306 - val_acc: 0.8864\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 6s 120us/sample - loss: 0.2108 - acc: 0.9201 - val_loss: 0.3290 - val_acc: 0.8822\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 6s 122us/sample - loss: 0.2021 - acc: 0.9233 - val_loss: 0.3196 - val_acc: 0.8895\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 6s 123us/sample - loss: 0.1951 - acc: 0.9273 - val_loss: 0.3171 - val_acc: 0.8922\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 6s 125us/sample - loss: 0.1885 - acc: 0.9286 - val_loss: 0.3208 - val_acc: 0.8903\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 6s 122us/sample - loss: 0.1812 - acc: 0.9312 - val_loss: 0.3312 - val_acc: 0.8924\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 6s 124us/sample - loss: 0.1764 - acc: 0.9336 - val_loss: 0.3384 - val_acc: 0.8888\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 6s 128us/sample - loss: 0.1699 - acc: 0.9364 - val_loss: 0.3445 - val_acc: 0.8882\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 6s 130us/sample - loss: 0.1646 - acc: 0.9378 - val_loss: 0.3333 - val_acc: 0.8880\n",
            "10000/10000 [==============================] - 1s 54us/sample - loss: 0.3546 - acc: 0.8841\n",
            "TRAIN: 48000 Validation: 12000\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 6s 134us/sample - loss: 0.5292 - acc: 0.8154 - val_loss: 0.4193 - val_acc: 0.8498\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 7s 142us/sample - loss: 0.3812 - acc: 0.8626 - val_loss: 0.3575 - val_acc: 0.8696\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 7s 152us/sample - loss: 0.3406 - acc: 0.8741 - val_loss: 0.3500 - val_acc: 0.8721\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 6s 128us/sample - loss: 0.3176 - acc: 0.8825 - val_loss: 0.3160 - val_acc: 0.8843\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 6s 125us/sample - loss: 0.2950 - acc: 0.8900 - val_loss: 0.3185 - val_acc: 0.8843\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 6s 128us/sample - loss: 0.2806 - acc: 0.8954 - val_loss: 0.3147 - val_acc: 0.8839\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 6s 127us/sample - loss: 0.2655 - acc: 0.9004 - val_loss: 0.3118 - val_acc: 0.8859\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 6s 125us/sample - loss: 0.2567 - acc: 0.9045 - val_loss: 0.2953 - val_acc: 0.8938\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 6s 132us/sample - loss: 0.2437 - acc: 0.9087 - val_loss: 0.2981 - val_acc: 0.8894\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 6s 132us/sample - loss: 0.2338 - acc: 0.9112 - val_loss: 0.2979 - val_acc: 0.8912\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 6s 132us/sample - loss: 0.2269 - acc: 0.9148 - val_loss: 0.3062 - val_acc: 0.8923\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 6s 127us/sample - loss: 0.2203 - acc: 0.9161 - val_loss: 0.3170 - val_acc: 0.8920\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 6s 133us/sample - loss: 0.2098 - acc: 0.9211 - val_loss: 0.3216 - val_acc: 0.8839\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 6s 132us/sample - loss: 0.2032 - acc: 0.9233 - val_loss: 0.3332 - val_acc: 0.8878\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 6s 128us/sample - loss: 0.1952 - acc: 0.9271 - val_loss: 0.2936 - val_acc: 0.8998\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 6s 135us/sample - loss: 0.1875 - acc: 0.9295 - val_loss: 0.3036 - val_acc: 0.8947\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 6s 127us/sample - loss: 0.1824 - acc: 0.9314 - val_loss: 0.3265 - val_acc: 0.8892\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 6s 128us/sample - loss: 0.1762 - acc: 0.9332 - val_loss: 0.3059 - val_acc: 0.8966\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 6s 131us/sample - loss: 0.1707 - acc: 0.9352 - val_loss: 0.3244 - val_acc: 0.8908\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 6s 126us/sample - loss: 0.1644 - acc: 0.9384 - val_loss: 0.3296 - val_acc: 0.8935\n",
            "10000/10000 [==============================] - 1s 55us/sample - loss: 0.3635 - acc: 0.8863\n",
            "TRAIN: 48000 Validation: 12000\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 7s 138us/sample - loss: 0.5290 - acc: 0.8135 - val_loss: 0.4574 - val_acc: 0.8354\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 6s 133us/sample - loss: 0.3805 - acc: 0.8610 - val_loss: 0.3536 - val_acc: 0.8758\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 6s 134us/sample - loss: 0.3381 - acc: 0.8749 - val_loss: 0.3446 - val_acc: 0.8723\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 6s 130us/sample - loss: 0.3130 - acc: 0.8841 - val_loss: 0.3218 - val_acc: 0.8873\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 6s 129us/sample - loss: 0.2948 - acc: 0.8905 - val_loss: 0.3168 - val_acc: 0.8865\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 6s 126us/sample - loss: 0.2803 - acc: 0.8951 - val_loss: 0.3187 - val_acc: 0.8869\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 6s 130us/sample - loss: 0.2672 - acc: 0.9006 - val_loss: 0.3086 - val_acc: 0.8893\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 6s 126us/sample - loss: 0.2561 - acc: 0.9049 - val_loss: 0.3124 - val_acc: 0.8905\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 6s 129us/sample - loss: 0.2440 - acc: 0.9072 - val_loss: 0.3145 - val_acc: 0.8906\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 6s 132us/sample - loss: 0.2333 - acc: 0.9111 - val_loss: 0.3104 - val_acc: 0.8957\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 6s 130us/sample - loss: 0.2263 - acc: 0.9140 - val_loss: 0.3098 - val_acc: 0.8910\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 6s 135us/sample - loss: 0.2162 - acc: 0.9187 - val_loss: 0.2995 - val_acc: 0.8966\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 6s 135us/sample - loss: 0.2088 - acc: 0.9208 - val_loss: 0.3130 - val_acc: 0.8907\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 6s 132us/sample - loss: 0.2009 - acc: 0.9248 - val_loss: 0.3154 - val_acc: 0.8965\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 6s 131us/sample - loss: 0.1949 - acc: 0.9262 - val_loss: 0.3127 - val_acc: 0.8960\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 6s 132us/sample - loss: 0.1881 - acc: 0.9289 - val_loss: 0.3122 - val_acc: 0.8976\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 6s 130us/sample - loss: 0.1816 - acc: 0.9314 - val_loss: 0.3110 - val_acc: 0.8963\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 7s 138us/sample - loss: 0.1736 - acc: 0.9337 - val_loss: 0.3488 - val_acc: 0.8892\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 6s 134us/sample - loss: 0.1698 - acc: 0.9356 - val_loss: 0.3380 - val_acc: 0.8930\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 6s 134us/sample - loss: 0.1617 - acc: 0.9380 - val_loss: 0.3282 - val_acc: 0.8978\n",
            "10000/10000 [==============================] - 1s 62us/sample - loss: 0.3585 - acc: 0.8863\n",
            "TRAIN: 48000 Validation: 12000\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 7s 146us/sample - loss: 0.5314 - acc: 0.8151 - val_loss: 0.4221 - val_acc: 0.8477\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 7s 140us/sample - loss: 0.3831 - acc: 0.8623 - val_loss: 0.3623 - val_acc: 0.8724\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 7s 144us/sample - loss: 0.3396 - acc: 0.8759 - val_loss: 0.3782 - val_acc: 0.8602\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 7s 138us/sample - loss: 0.3154 - acc: 0.8823 - val_loss: 0.3255 - val_acc: 0.8834\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 7s 136us/sample - loss: 0.2948 - acc: 0.8904 - val_loss: 0.3400 - val_acc: 0.8776\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 7s 137us/sample - loss: 0.2809 - acc: 0.8961 - val_loss: 0.3790 - val_acc: 0.8637\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 7s 139us/sample - loss: 0.2680 - acc: 0.9009 - val_loss: 0.3177 - val_acc: 0.8859\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 7s 140us/sample - loss: 0.2566 - acc: 0.9029 - val_loss: 0.3237 - val_acc: 0.8842\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 6s 135us/sample - loss: 0.2438 - acc: 0.9096 - val_loss: 0.3258 - val_acc: 0.8865\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 8s 168us/sample - loss: 0.2331 - acc: 0.9130 - val_loss: 0.3109 - val_acc: 0.8920\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 7s 142us/sample - loss: 0.2249 - acc: 0.9155 - val_loss: 0.3147 - val_acc: 0.8883\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 7s 141us/sample - loss: 0.2180 - acc: 0.9187 - val_loss: 0.3193 - val_acc: 0.8894\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 6s 127us/sample - loss: 0.2089 - acc: 0.9215 - val_loss: 0.3225 - val_acc: 0.8907\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 6s 131us/sample - loss: 0.1994 - acc: 0.9259 - val_loss: 0.3319 - val_acc: 0.8889\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 6s 127us/sample - loss: 0.1927 - acc: 0.9270 - val_loss: 0.3290 - val_acc: 0.8885\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 6s 124us/sample - loss: 0.1889 - acc: 0.9288 - val_loss: 0.3228 - val_acc: 0.8938\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 6s 134us/sample - loss: 0.1803 - acc: 0.9321 - val_loss: 0.3363 - val_acc: 0.8910\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 6s 128us/sample - loss: 0.1722 - acc: 0.9352 - val_loss: 0.3621 - val_acc: 0.8889\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 6s 128us/sample - loss: 0.1693 - acc: 0.9360 - val_loss: 0.3369 - val_acc: 0.8958\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 6s 123us/sample - loss: 0.1622 - acc: 0.9389 - val_loss: 0.3571 - val_acc: 0.8893\n",
            "10000/10000 [==============================] - 1s 58us/sample - loss: 0.3793 - acc: 0.8853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-vXOp4iWrlO-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "eecb1c96-07bf-4d1c-9406-b2f263485180"
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(test_preds)):\n",
        "  print(\"{}th Model: loss={} accuracy={}\".format(i,log_loss(test_labels,test_preds[i]),accuracy_score(test_labels,np.argmax(test_preds[i],axis=1))))\n",
        "\n",
        "kfold_test_preds = np.average(np.array(test_preds),axis=0)\n",
        "print(\"KFold Average Model: loss={} accuracy={}\".format(log_loss(test_labels,kfold_test_preds),accuracy_score(test_labels,np.argmax(kfold_test_preds,axis=1))))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0th Model: loss=0.3657217438034511 accuracy=0.8861\n",
            "1th Model: loss=0.3571766391156306 accuracy=0.8841\n",
            "2th Model: loss=0.3653581034124332 accuracy=0.8863\n",
            "3th Model: loss=0.35969854553753167 accuracy=0.8863\n",
            "4th Model: loss=0.38154356260789224 accuracy=0.8853\n",
            "KFold Average Model: loss=0.2804664349198927 accuracy=0.9036\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}